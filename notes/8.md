# If Statements

## Lexing

We are going to use the following source string as our test case:

```py
a = 10
if False:
    a = 20
a
```

We find that our lexer produces incorrect tokens for this string:

```diff
@@ -11,6 +11,7 @@
 TokenInfo(type=55 (OP), string='=', start=(3, 6), end=(3, 7), line='')
 TokenInfo(type=2 (NUMBER), string='20', start=(3, 8), end=(3, 10), line='')
 TokenInfo(type=4 (NEWLINE), string='\n', start=(3, 10), end=(3, 11), line='')
-TokenInfo(type=1 (NAME), string='a', start=(4, 0), end=(5, 0), line='')
-TokenInfo(type=6 (DEDENT), string='', start=(5, 0), end=(5, 0), line='')
+TokenInfo(type=6 (DEDENT), string='', start=(4, 0), end=(4, 0), line='')
+TokenInfo(type=1 (NAME), string='a', start=(4, 0), end=(4, 1), line='')
+TokenInfo(type=4 (NEWLINE), string='', start=(4, 1), end=(4, 2), line='')
 TokenInfo(type=0 (ENDMARKER), string='', start=(5, 0), end=(5, 0), line='')
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "<snip>/vpy/test_lex.py", line 92, in <module>
    main()
    ~~~~^^
  File "<snip>/vpy/test_lex.py", line 68, in main
    assert process("a = 10\nif False:\n    a = 20\na")
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError
```

One issue is that we copy the end position for the tokens after doing lookahead when queuing `dedent`s, meaning the "current" token ends up in the wrong place (in the example, this is the `NAME` token which ends at `5:0` instead of `4:1`). We solve this by saving the end position (i.e. `copy(self.pos)`) to a variable before we deal with dedenting. The new result is:

```diff
@@ -11,6 +11,7 @@
 TokenInfo(type=55 (OP), string='=', start=(3, 6), end=(3, 7), line='')
 TokenInfo(type=2 (NUMBER), string='20', start=(3, 8), end=(3, 10), line='')
 TokenInfo(type=4 (NEWLINE), string='\n', start=(3, 10), end=(3, 11), line='')
+TokenInfo(type=6 (DEDENT), string='', start=(4, 0), end=(4, 0), line='')
 TokenInfo(type=1 (NAME), string='a', start=(4, 0), end=(4, 1), line='')
-TokenInfo(type=6 (DEDENT), string='', start=(5, 0), end=(5, 0), line='')
+TokenInfo(type=4 (NEWLINE), string='', start=(4, 1), end=(4, 2), line='')
 TokenInfo(type=0 (ENDMARKER), string='', start=(5, 0), end=(5, 0), line='')
```

The next issue is that dedenting does not trigger at the identifier token. Instead, the `dedent` token that we see is from end-of-file cleanup (you can tell by the computed position of the token). The reason for this is we skipped dedenting tokens that immediately preceed a new line (i.e. occur at the end of a line). We originally added this to avoid emitting `dedent`s on completely empty lines, but turns out this is actually unnecessary since we handle `newline` tokens which occur at the start of the line in the outer conditional and they never make it to the dedent logic. We can remove the lookahead and the associated code entirely.

```diff
@@ -11,7 +11,7 @@
 TokenInfo(type=55 (OP), string='=', start=(3, 6), end=(3, 7), line='')
 TokenInfo(type=2 (NUMBER), string='20', start=(3, 8), end=(3, 10), line='')
 TokenInfo(type=4 (NEWLINE), string='\n', start=(3, 10), end=(3, 11), line='')
+TokenInfo(type=6 (DEDENT), string='', start=(4, 0), end=(4, 0), line='')
 TokenInfo(type=1 (NAME), string='a', start=(4, 0), end=(4, 1), line='')
-TokenInfo(type=6 (DEDENT), string='', start=(4, 0), end=(4, 0), line='')
 TokenInfo(type=4 (NEWLINE), string='', start=(4, 1), end=(4, 2), line='')
 TokenInfo(type=0 (ENDMARKER), string='', start=(5, 0), end=(5, 0), line='')
```

Now the `dedent` has the correct location but is in the wrong spot in the token stream. This is because, while we schedule the dedents correctly, the lexing function returns the `identifier` token directly, bypassing the queue. We change the code to schedule the identifier first, then compute the dedents, then return whatever ends up on the top of the stack.

This finally produces a clean parse both for the `if` smoketest, the big problem file we are trying to parse, and all the old smoketests.

## Parsing

First we define the AST nodes: [`compound_stmt`,](https://docs.python.org/3.13/reference/compound_stmts.html#grammar-token-python-grammar-compound_stmt) [`if_stmt`,](https://docs.python.org/3.13/reference/compound_stmts.html#grammar-token-python-grammar-if_stmt) [`assignment_expression`,](https://docs.python.org/3.13/reference/expressions.html#grammar-token-python-grammar-assignment_expression) [`suite`.](https://docs.python.org/3.13/reference/compound_stmts.html#grammar-token-python-grammar-suite) We also introduce a dedicated node for [`expression`](https://docs.python.org/3.13/reference/expressions.html#grammar-token-python-grammar-expression) because it is referenced here while in the previous chapters we inlined it. Additionally, we override the return type of the `to_ast` methods of all expression nodes with `ast.expr` (or more even specific types where it's easy) to remove a bunch of type assertions. Likewise we switch to `ast.stmt` for `to_ast` of statement nodes.

Then we add parsing functions. Three things of note:

1. this is the first time we consume indentation tokens,
2. we add a `expect_identifier` function to match keywords like `if`,
3. there is a typo in the `AstLiteral.to_ast` method where we turned `False` literals into `True`.

---

Before we move on, let's try removing the indentation after the `if`:

```py
a = 10
if False:
a = 20
a
```

We get an error, as expected:

```
vpy.parse.ParseFailedError: expected <indent>, found <identifier>
Parse function: suite
Parse function: if_stmt
Parse function: compound_stmt
Parse function: statement
Parse function: file_input

a = 20
 ^
```

It is mostly readable in this case but it has a couple of issues. The first is that the arrow points at the wrong position. The second is that if we switch the order in which we try to parse the various `statement` types (by attempting `compound_statement` before `stmt_list`), we get a much worse error:

```
vpy.parse.ParseFailedError: expected <newline>, found <whitespace>
Parse function: statement
Parse function: file_input

if False:
   ^
```

To a human reader it's obvious that the former error is more "correct" because the `if` keyword inambiguously dictates that an indented block must follow. But the parser simply tries things in order and backtracks if it fails. To improves messages in such cases, we will later design some way of committing to an AST node when trying a checkpoint, making failures after a certain token has been parsed fatal (such as the `if` keyword) and having them prevent backtracking and raise to the top.

## Interpreting

Simply implemet all the new node types. Note that we have to add an `expression` node interpreter to pass old tests since that is now in a lot of expression parse trees.

Also test with `if True` to check that both cases work as expected.

## Compiling

We will need to generate label names for branching in the `if` statement. We will use the variable index, since [LLVM does something similar for unnamed blocks:](https://releases.llvm.org/11.0.0/docs/LangRef.html#functions)

> ... If an explicit label name is not provided, a block is assigned an implicit numbered label, using the next value from the same counter as used for unnamed temporaries (see above). For example, if a function entry block does not have an explicit label, it will be assigned label “%0”, then the first unnamed temporary in that block will be “%1”, etc. If a numeric label is explicitly specified, it must match the numeric label that would be used implicitly.

We rename `next_var` to `next_id` to make its new purpose clear.

---

When we implement branching in a straight-forward way, we produce the following IR:

```llvm
define i64 @test() {
  ; a = 10
  %.2 = bitcast i64 10 to i64
  %a.1 = bitcast i64 %.2 to i64

  ; if False:
  ;     a = 20
  %.3 = bitcast i64 0 to i64
  %if.cond.i1.4 = icmp eq i64 %.3, 1
  br i1 %if.cond.i1.4, label %if.then.5, label %if.end.6

  if.then.5:
  ; a = 20
  %.8 = bitcast i64 20 to i64
  %a.7 = bitcast i64 %.8 to i64

  br label %if.end.6

  if.end.6:

  ; a

  ret i64 %a.7
}
```

This fails to compile with this error:

```
Instruction does not dominate all uses!
  %a.7 = bitcast i64 %.8 to i64
  ret i64 %a.7
```

This is because %a.7 is local to the `if.then.5` block, which might not run at all, and so is not accessible from the `if.end.6` block. We need to use [the `phi` instruction](https://llvm.org/docs/LangRef.html#phi-instruction) to make sure any variables which differ in binding between the two branches end up merged in the follow-up to the `if`:

```
define i64 @test() {
  start:

  ; <snip>

  if.end.6:

  %a.9 = phi i64 [ %a.7, %if.then.5 ], [ %a.1, %start ]
  ; a

  ret i64 %a.9
}
```

The `phi` instruction will multiplex the value based on which block ran before. In our case, if the `if` runs, then this block will be `if.then.5`. If it does not run, then it will be the block before the if block, which is the start of the function in the example (which we define as `%start` for convenience).

To implement this, we need to keep track of a couple of things:

1. the current block name (so we can refer to the block right before the if),
2. the set of all variables which have changed within the if statement's body so we can emit `phi` for them,
3. and a copy of the variable bindings from before the `if` body, so we can refer to them in the generated `phi`s.

Tracking the block is trivial. We start with `%start` and update it whenever we emit a block (which is only during `if` statements right now). Note that we have to make sure the body of the `if` generates with the correct previous-block value to support nesting `if`s and other branching constructs. We implement an `emit_block` method to make sure we never forget to update the current block.

For tracking the local bindings before the body, we `copy(self.locals)` before we emit anything.

Finally, we simply compare the locals before and after the body to see which variables changed.

Again, test both with `if False` and `if True` to make sure everything works as expected.

Note: our solution assumes that the if condition never modifies any variables which is not generally true e.g. because Python allows assignment expression like in `if (a := 3) == 3:`

---

We could also do without the `phi` instruction by rewriting our variable handling code to use `alloca` and `store`/`load` to store the variables on the stack and access them by pointer. This has unobvious trade-offs since it's unclear if the LLVM optimizer would always eliminate the pointer accesses in favor of using registers or if we are spilling from registers to the stack already anyway. We might go with this solution later but for now it's more interesting to try to deal with a true single-assigment approach.

# Aside: Command Line Driver

To help debug the lexing and parsing stages, we implement a small command-line tool in `__main__.py` that takes an input string and supports lexing it (with out lexer or the CPython one) or parsing it, then dumping the results to the terminal. We will build this tool up over time to include other ways to use the compiler interactively.
