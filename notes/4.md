# Parsing Test Suite

Before we move on from `1 + 2` to more complicated source codes (including dealing with recursive syntax trees, associativity etc.), we want to compare our output to [the standard library parsing output from the `ast` module.](https://docs.python.org/3/library/ast.html#ast.parse) We will again need to write conversions between our AST representation and the standard library one.

The parse tree produced by `ast` using [`ast.dump`](https://docs.python.org/3/library/ast.html#ast.dump) is:

```
Module(
  body=[
    Expr(
      value=BinOp(
        left=Constant(value=1),
        op=Add(),
        right=Constant(value=2)))])
```

We are going to go top-to-bottom, first converting our `file_input` to `ast.Module`, then `statement/stmt_list/simple_stmt/expression_stmt` to `Expr` etc. Note that some nodes are 1-to-1 while others require us to flatten the hierarchy of the official grammar to the processed AST nodes of the standard library. The reason the standard library AST is flatter is due to not having to deal with operator precedence and limitations of the PEG parser (e.g. when encoding right recursion). We will define a class for each node to contain the convertor implementation, named `to_ast`.

When making the classes, we name and give types to all the fields. Some fields are lists of other nodes, so we patch the `to_str` function to recognize this case when looking for field names (we iterate any lists and save the field name for the `id` of each element which is a `Node`). A lot of our nodes end up with a single field `x` stores their only child, which is due to them simply representing a choice in the grammar.

We have now to keep track of the operator in `AExpr` so we introduce a field for it. We will need to represent the fact that `op` and `rhs` always go together to avoid representing invalid states, but for now we will just do this with an assert.

Notes:

1. this process actually revelas a couple minor bugs from step 3—`power` nodes directly contained an `atom` rather than a `primary`, and `m_expr` had an outdated implementation with manual `children` tracking
2. we have to rename `Literal` nodes (to `AstLiteral`) to avoid clashing with `typing.Literal`

---

We write a `test_parse.py` file in a way analogous to `test_lex.py`. Again we use `1 + 2` as a smoketest, and `tokenize` from the standard library as our big test. As expected, we do not parse the latter test since even our lexer cannot handle that file yet.

---

One more thing we'd like to test is the ability to un-parse our AST. We will write a generic `unparse` function on our `Node` class that will recursively `unparse` all children. The `unparse` of a token is simply its text. Then we will compare the result of `unparse` to the input source code for all test cases. Since we insert a `\n` at end of all inputs, we will need to do so in our test as well. We will fix this very minor imperfection at a later time.

# Parser Errors

We will now try to parse `1 + 2 + 3`. We add it to both the lexing and parsing test suites. Lexing works great, but parsing fails with an error:

```
RuntimeError: expected <newline>
```

This is not terribly helpful, so let's try to improve the error messages before we go further.

The first, simple thing we can do, is adjust our `parse_function` decorator to add the name of the parse function to all exceptions via [`add_note`:](https://docs.python.org/3/library/exceptions.html#BaseException.add_note)

```
RuntimeError: expected <newline>
Parse function: statement
Parse function: file_input
```

This already tells us quite a bit more. We could have looked for all our parsing functions in the call stack, but this makes it immediately apparent where in the tree the parser was.

Now we will include the currently parsed line and a little `^` symbol to indicate our parsing position (a cursor). We add a function to the lexer called `debug_pos` which returns a tuple of two lines—the current line and the cursor line. We search for `\n` (or `\r`, or `\n\r`, todo for now) in either direction from the current position and then cut the line down to fit within 80 characters with some room before and after the cursor. We use the UTF-8 ellipsis character `…` to indicate when the line is cut off in either direction without taking more than 1 character of space in the output. Remember that we can unconsume tokens in the parser so the lexer position does not necessarily represent the next token to be consumed. Because of this, we write the function as optionally taking a position argument which will in the case of the parser be the next token in the pushback stack.

One final thing we do is rewrite `expect` to print the found token type in addition to the expected token type.

After these two fixes, the error now looks like this:

```
RuntimeError: expected <newline>, found <whitespace>
Parse function: statement
Parse function: file_input
1 + 2 + 3
     ^
```

# Associativity, Left-recursive and Right-recursive Grammars

Finally, let's deal with the actual parse error. Nowhere in our parsing functions did we account for the possibility that a `+` operator is applied in sequence. Since the result of the operation does not depend on the order in this case, there are two possible parses—the left-associative `(1 + 2) + 3` and the right-associative `1 + (2 + 3)`. Addition is a fully associative operation so there is actually no difference between the two interpretations (this is also why it is mathematically associative). Meanwhile, subtraction is a left-associative operation: `3 - 2 - 1 = (3 - 2) - 1 != 3 - (2 - 1)` and certain exotic operations can be right-associative.

This concept is related to the recursion direction in parsing grammars. Consider the following two grammars for addition:

```
add_l := integer | add_l "+" integer
add_r := integer | integer "+" add_r
```

`add_l` is left-recursive and `add_r` is right-recursive. The exact definition is that a rule is left-recursive if it occurs as the first symbol on the left in its definition, and right-recursive if it occurs as the first symbol on the right in its definition. Different parsing algorithms can only handle one or the other. The left-recursive grammar produces left-associative operators (`1 + 2 + 3 = add_l(add_l(1 + 2) + 3)`) and the right-recursive one produces right-associate operators (`1 + 2 + 3 = add_r(1 + add_r(2 + 3))`).

The Python grammar is defined in a left-recursive way, e.g. `a_expr := a_expr "+" m_expr | ...` This is not possible to parse with recursive descent because it produces infinite recursion as in the pseudocode example below:

```py
def a_expr(self) -> Node:
    left = a_expr() # <<<
    op = opt("+")
    if op is None:
      return left
    right = m_expr()
    return left, op, right
```

Right recursion (`a_expr := m_expr "+" a_expr | ...`) works fine in recursive descent since the base case is easily detected by the "+" token before we hit the recursive branch:

```py
def a_expr(self) -> Node:
    left = m_expr() # <<<
    op = opt("+")
    if op is None:
      return left
    right = a_expr()
    return left, op, right
```

We are going to have to redefine the grammar in a right-recursive way, then reorganize our nodes to produce the original grammar. We could keep the right-recursive organization, but then the interpreter and compiler would have to deal with reversing it for left-associative operators (like subtraction) and we wouldn't match the parses from the standard library.

These concepts are also related to LL and LR parsers, which cannot handle left and right recursion respectively. And those, in turn, to the ideas of left-most and right-most derivation. Another related pair of ideas is top-down and bottom-up parsing. Recursive descent happens to be super flexible, but has properties most similar to the LL parser (top-down, left-most derivation, cannot handle left-recursive grammars). There are also parallels here with left-fold [(`reduce`)](https://docs.python.org/3/library/functools.html#functools.reduce) and right-fold from functional programming. These are actually quite useful as we'll see below.

The naive way is to parse right-recursively, then reverse the entire tree. Let's consider how we might do this:

```
# right-recursive (input)
# 1 + (2 + (3 + ...))
plus
  lhs = 1 # "left-hand-side"
  rhs =   # "right-hand-side"
    plus
      lhs = 2
      rhs =
        plus
          lhs = 3
          rhs = ...

# left-recursive (goal)
# ((1 + 2) + 3) + ...
plus
  lhs =
    ...
      lhs =
        plus
          lhs =
            plus
              lhs = 1
              rhs = 2
          rhs = 3
      rhs = ...
  rhs = ...
```

The key insight is that we can immediately make the deepest node:

```py
# self = 1 + (2 + (3 + ...))
cur = Node(
    lhs=self.lhs, # 1
    rhs=self.rhs.lhs # 2
) # 1 + 2
```

then we can recurse into our right-hand side (`self.rhs`), and make the second-deepest node, using the previous result:

```py
# self = 2 + (3 + ...)
cur = Node(
    lhs=cur, # 1 + 2
    rhs=self.rhs.lhs # 3
) # (1 + 2) + 3

# note that we are not using `self.lhs`, because it is already part of `cur`
```

We can repeat this until we reach the end of the input, at which point we output the current node. In code:

```py
def convert(x: Node, *, cur: Node | int | None = None):
    if cur is None:
      cur = x.lhs

    if not isinstance(x.rhs, Node):
        return cur

    return convert(x.rhs, cur=Node(lhs=cur, rhs=self.rhs.lhs))
```

Note: this is a tail-recursive function so we can also write it iteratively to avoid crashing due to stack depth limits on large inputs:

```py
def convert(x: Node):
    cur = x.lhs
    while isinstance(x.rhs, Node):
        cur = Node(lhs=cur, rhs=x.rhs.lhs)
        x = x.rhs

    return cur
```

---

We will now apply this approach to `a_expr` to make it produce left-recrusive ASTs. First, we will wrap the starting `m_expr` into an `a_expr` with just the RHS and no LHS or operator, to serve as the initial value for the accumulator:

```py
lhs = AExpr(type="a_expr", lhs=None, op=None, rhs=self.m_expr())
```

Then we will check if the following non-whitespace token is `+`. If it is not, we simply return our accumulator `lhs` since there is nothing else to add to this `a_expr`. Otherwise, we parse out the operator _and its RHS `m_expr`_ and update the accumulator:

```py
lhs = AExpr(type="a_expr", lhs=lhs, op=op, rhs=rhs)
```

Then we repeat the check. This continues until we hit the base case (we are not followed by an operator).

Essentially the design goes from "parse the LHS, then recurse for the RHS" to "parse the base case, then iterate on the continuation of the expression". Whereas the former case uses the call stack to accumulate the data for the return values (it stores the LHS and the operator while we recurse), in the latter case we explicitly keep track of `lhs`.

## Trackin Children

One final thing we have to deal with to support left-recursion is child tracking. When we try to call `to_str` on the AST produced by the parser after just the above changes (with `1 + 2 + 3` as the input), we realize that the inner node does not have any children attached at all, since our automatic tracking does not apply mid-function. We can fix this by manually attaching `self.children` to `lhs` after we update it in the loop.

Looking again after the fix, we can see another problem—we attach the first `m_expr` node twice, to both the inner and the outer `a_expr` nodes. This is because we also need to reset `self.children` to `[]` on each iteration after we use it, just as the automatic tracking would do.

Unfortunately, this fix ends up causing a different problem. The inner `lhs` node is completely lost from the AST serialization, as it never became a child of anything (it is still in the `lhs` field, but we need it to also be in the `children` array). Instead of resetting to an empty list, we set `self.children = [lhs]` so the `lhs` gets included correctly on the next iteration.

Now we hit `RecursionError: maximum recursion depth exceeded`. This is really confusing to debug, but it happens somewhere inside `to_str`. To help diagnose the issue, we adjust `to_str` by adding a `visited` set, tracking the `id` of each node we visit, so we can output a special string (`<recursion: {type}#{id}>`) when we hit a node that would cause infinite recursion. (We also add `#{id}` after the node type and change to `.` as the field name prefix.) We see now that the issue is that the top-level `a_expr` has _itself_ as a child:

```
file_input#4536424432{
  .xs: statement#4536424096{
    .x: stmt_list#4536423760{
      ...
        shift_expr#4536421408{
          .rhs: a_expr#4536049232{
            <recursion: a_expr#4536049232>
          }
        }
      ...
    }
    newline@1:10#9'\n'
  }
}
```

This problem came up because, on the last iteration, `lhs` gets returned and `parse_function` attaches the current children accumulator to it, _which we just set to `[lhs]`,_ so `lhs` is now a child of `lhs`. Since in `a_expr` we want to handle the children attach manually, we will adjust `parse_function` to only auto-attach the accumulator if the node has no children at the time of return.

One final issue is that the base case node (the one we parse unconditionally) does not get correct children. We can fix this most easily by creating another function (called `a_expr_base`) wrapped in `parse_function` to handle the child attachment.

The final AST output is as follows:

```
file_input#4540307104{
  .xs: statement#4540306768{
    .x: stmt_list#4540306432{
      .xs: simple_stmt#4540306096{
        .x: expression_stmt#4540305760{
          .x: starred_expression#4540305424{
            .x: or_expr#4540305088{
              .rhs: xor_expr#4540304752{
                .rhs: and_expr#4540304416{
                  .rhs: shift_expr#4540304080{
                    .rhs: a_expr#4540160656{
                      .lhs: a_expr#4540158416{
                        .lhs: a_expr#4540303744{
                          .rhs: m_expr#4540303408{
                            .rhs: u_expr#4540303072{
                              .x: power#4540302736{
                                .x: primary#4540302400{
                                  .x: atom#4540302064{
                                    .x: literal#4540301728{
                                      .x: decinteger@1:1#0'1'
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        whitespace@1:2#1' '
                        .op: operator@1:3#2'+'
                        whitespace@1:4#3' '
                        .rhs: m_expr#4540158096{
                          .rhs: u_expr#4540157776{
                            .x: power#4540157456{
                              .x: primary#4540157136{
                                .x: atom#4540156816{
                                  .x: literal#4540156496{
                                    .x: decinteger@1:5#4'2'
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                      whitespace@1:6#5' '
                      .op: operator@1:7#6'+'
                      whitespace@1:8#7' '
                      .rhs: m_expr#4540160336{
                        .rhs: u_expr#4540160016{
                          .x: power#4540159696{
                            .x: primary#4540159376{
                              .x: atom#4540159056{
                                .x: literal#4540158736{
                                  .x: decinteger@1:9#8'3'
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
    newline@1:10#9'\n'
  }
}
```

This is a bit hard to read and, unfortunately, `unparse` does not help us tell if the result is properly left-recursive since it does not show precedence information. We add a parameter to `unparse` that will unconditionally inject parentheses around binary operator nodes. With this setting enabled, the result of unparsing the above AST is `(((1) + 2) + 3)` as expected.

---

Note: we make one more change to `to_str` in this chapter to allow our field name detection to work with `Token`s for the `op` field of `AExpr` to print properly.
