# Interpreting

In following with our goal of testing each step end-to-end before adding new features, we will now tackle interpreting and compiling the simple addition expressions like `1 + 2 + 3`.

We define an `Interpreter` class which will contain no state for now (but will later deal with, for example, the mapping of variables to values). It includes two functionsâ€”one for interpreting statements, and one for interpreting expressions. Statements do not have values in Python, so that function always returns `None`. Expression interpretation returns the value of the expression.

We match our AST nodes with specific types using `isinstance`. Most of our nodes are dummies holding a single child which we recurse into. For expressions, we have actual implementations for `a_expr` and literal (`AstLiteral`):

```py
if isinstance(x, AExpr):
    if x.lhs is None:
        return self.eval(x.rhs)

    assert x.op.text == "+"

    return self.eval(x.lhs) + self.eval(x.rhs)

...

if isinstance(x, AstLiteral):
    assert x.x.type == "decinteger"
    return int(x.x.text)

...
```

We want write a quick test file for interpretation as we did for each step before, comparing our result with the result from Python's built-in [`eval`](https://docs.python.org/3/library/functions.html#eval). We need to use the `Interpreter.eval` method from our implementation so we can get access to the value of the test expression; since, again, statements do not have values and we cannot get to it another way by e.g. storing the result in a variable, until we implement them. To do this, we also need to be able to parse just a single expression since the `Interpreter.eval` method does understand statement nodes like `simple_stmt`. We add a `Parser.parse_expr` method, and move some of the exception notes logic into a contextmanager for sharing with `Parser.parse`.

Our script is also relying on simple equality comparison for now, but we will need to switch to a serialization format like [`pickle`](https://docs.python.org/3/library/pickle.html) to compare classes, functions, etc. when we implement them; or rely on some proxy metric (like the result of a run of an algorithm, or the values in its intermediate steps) to figure out if our interpreter is accurate.

We are also not able to easily use the standard library source files as test cases anymore as most of them do not calculate anything and only define modules, functions, global variables, etc. We will include custom test cases and a way to load them from files later. We will also use these test cases for compilation testing, when we add them.

```
$ python -m vpy.test_interpret
1 + 2 + 3

Evaluated:
6
Reference:
6
Matches

!!! Leftover tokens:
newline@1:10#9'\n'
```

# Compiling

We will compile to [LLVM IR](https://releases.llvm.org/11.0.0/docs/LangRef.html) to benefit from low-level optimization and various final targets that it supports: we get x86, ARM, RISC-V etc. all fo free. We start with installing the [llvmlite library](https://llvmlite.readthedocs.io/en/latest/) from [the Numba project.](https://numba.pydata.org/) This includes bindings to LLMV's JIT compiler that we will use to turn our generated LLVM IR into runnable code. We are not going to use the LLVM IR builder API for now, instead we will output raw strings. This is to avoid a strict dependency on the library (we could just write the output to a file and let an external compiler deal with it) and get "lower down" the stack of technologies here. We might switch to the builder API later.

We create a `Compiler` class which will contain the necessary state to emit lines of LLVM IR and manage indentation. The rest of it follows the approach used in `Interpeter` but expressions return the name of a LLVM intermediate variable instead of the expression itself.

We are going to assume that all values in the program are `i64` for now to avoid dealing with types, value boxing/unboxing, etc. but note that Python is a dynamically typed language so this definitely will need changing in the future. For example, we transform `+` into the `add` instruction, but really the chosen instruction should depend on the type of the arguments as you can e.g. add strings `"hello " + "world"`. To avoid dealing with immediate arguments (the conventional way to write `1 + 2` is `%1 = add i64 1, 2`), we store all intermediate results in temporary variables, and use no-op `bitcast` calls to define "constant local variables":

```
%1 = bitcast i64 1 to i64  ; no-op cast, local "constant" equal to 1
```

We also wrap the emitted code in a `test` routine that returns `i64` for now, but will again need to build type-specific comparison code and/or read variables from memory to analyze the results of running our compiled IR. To call the function we use `ctypes` as recommended in the llvmlite tutorial.

The final output is as follows:

```
define i64 @test() {
  %1 = bitcast i64 1 to i64
  %2 = bitcast i64 2 to i64
  %3 = add i64 %1, %2
  %4 = bitcast i64 3 to i64
  %5 = add i64 %3, %4

  ret i64 %5
}

test() = 6
```
